{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge as SklearnRidge\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../ToyotaCorolla.csv')\n",
    "\n",
    "df = data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['KM', 'Weight', 'Age_08_04']]\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, shuffle= True, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 22 iterations.\n",
      "Predicted prices: [ 8.37938566e+02 -2.09182131e+03 -5.98711838e+02 -2.02708390e+03\n",
      " -7.97637371e+02 -3.22406476e+03 -2.26956277e+03 -2.56862115e+03\n",
      "  3.15083889e+03  2.31475333e+03 -1.68600436e+03 -1.56099518e+03\n",
      "  2.06830864e+03  2.57019566e+03 -1.30765158e+03 -2.06099337e+03\n",
      "  1.71650520e+03  6.97568004e+03 -3.95600156e+03 -1.73171557e+03\n",
      "  1.84970812e+03  7.02686782e+03 -3.06405610e+03 -4.00459346e+01\n",
      " -3.08908516e+03  5.17143392e+03 -8.04840632e+02 -3.97676402e+03\n",
      "  5.02295306e+03  3.72262277e+03 -2.90237347e+03 -1.03161893e+03\n",
      " -2.43641731e+03 -8.82120472e+02 -6.59314289e+02 -3.00184255e+03\n",
      " -2.15116550e+03 -1.01819966e+03  5.70134346e+03 -1.68791287e+03\n",
      " -1.02862529e+03 -1.39316010e+03 -3.11817878e+03 -5.36228134e+03\n",
      " -3.58522236e+03  6.13567272e+03 -1.55272001e+03 -3.14718740e+02\n",
      " -1.52014827e+03  2.74866226e+03  2.22527147e+03 -3.98226159e+03\n",
      "  4.10078744e+03  5.43939127e+03 -4.67524176e+03 -3.34286740e+03\n",
      " -5.42288873e+02 -2.04871126e+02  5.17895654e+03  5.54335627e+03\n",
      "  1.51367907e+03 -1.96968082e+03 -3.26594728e+03  2.57272207e+02\n",
      "  2.46944558e+03 -2.19988487e+03  3.45155288e+03 -3.72473993e+03\n",
      " -2.94457431e+03 -5.29630534e+01  6.82901556e+03 -3.85490083e+00\n",
      "  2.18296922e+03 -3.49791769e+03  7.91908636e+03  2.90334484e+03\n",
      " -1.79159079e+03 -3.65835612e+03 -4.23817143e+02 -1.71636127e+03\n",
      " -7.03793741e+02 -2.46042542e+03 -6.69540447e+02 -1.18812728e+02\n",
      " -2.76048157e+03 -4.22248060e+03  3.03179591e+02  2.17582272e+03\n",
      " -1.41068423e+03 -7.47148812e+01 -2.35725649e+03 -3.90471032e+03\n",
      " -4.19301842e+02 -6.88713175e+01  1.89659633e+03 -1.77874181e+03\n",
      "  1.14631803e+04 -3.05451133e+03  3.30507626e+03 -1.84992575e+03\n",
      "  6.54072582e+01 -1.22562927e+03 -3.21992262e+02  6.12445336e+03\n",
      " -1.99977812e+03 -3.48677256e+03  6.13593290e+03 -2.49194001e+03\n",
      " -1.20829720e+03 -1.35237846e+03  8.40211028e+02  6.23260905e+02\n",
      " -1.04156406e+03  3.02238688e+03 -1.54535160e+03 -2.29306788e+03\n",
      " -4.01620115e+03  2.62464774e+03  1.69334714e+03  3.01979381e+03\n",
      " -3.27463520e+03 -3.10338697e+03 -2.01914952e+03  4.46305336e+03\n",
      "  1.13958666e+03 -1.24742950e+03  2.69395622e+03 -9.56132140e+02\n",
      " -2.56298409e+03  2.66498699e+03  1.43091300e+02  4.92697666e+03\n",
      " -2.71821344e+02 -8.56071426e+02 -3.89499096e+03 -1.36074349e+03\n",
      "  1.17434391e+02  7.77485834e+02 -2.64246619e+03 -6.03626305e+03\n",
      "  1.53686398e+03 -6.25590561e+02  1.42132891e+03 -2.62209019e+03\n",
      "  1.36501788e+03  5.42906782e+02 -4.12366054e+03 -2.32789155e+03\n",
      " -2.93880643e+03  8.53654093e+02 -5.86435115e+02  5.09397714e+03\n",
      " -1.79063649e+03 -1.72108420e+03  3.63509253e+02  1.80603861e+02\n",
      " -2.38592066e+03  2.39234266e+03  7.74790542e+01  8.72035675e+03\n",
      "  5.50045518e+02  5.17742333e+03  4.67825821e+03 -3.33651698e+03\n",
      " -2.04571901e+03  2.00944830e+03 -3.00314542e+03  2.65327597e+03\n",
      " -1.83084827e+03 -2.83403543e+03 -2.20867754e+03  1.42211869e+03\n",
      " -1.64550334e+03  2.02452196e+03 -7.90602283e+01 -9.64475214e+02\n",
      "  6.12668146e+03 -3.36724905e+02 -1.20057007e+03 -2.66217883e+02\n",
      "  1.44748939e+03  2.25269054e+02  2.87001427e+03 -3.19340283e+03\n",
      " -1.90293912e+03 -3.39600277e+03 -4.49502102e+03 -2.07881393e+03\n",
      " -1.39560677e+03 -6.00691883e+02 -1.70439611e+03 -3.55637494e+03\n",
      " -5.21541787e+03  6.69552323e+02 -4.61679443e+02 -2.16253851e+01\n",
      " -4.17814991e+03 -3.21174232e+03 -6.06981903e+02  6.79957026e+03\n",
      " -8.92771638e+02 -2.66102343e+03 -3.43981594e+03 -2.37197332e+03\n",
      "  5.15522337e+03  6.58682894e+03 -4.55869031e+02 -9.60642184e+02\n",
      "  1.12296590e+02 -1.24350173e+03 -2.06006101e+03  2.69138843e+02\n",
      " -1.00384298e+03 -7.22035687e+02 -4.28716081e+03  8.24243281e+02\n",
      " -2.54261629e+03 -1.73239466e+03 -3.04916650e+03  5.55545153e+02\n",
      " -1.64254856e+03 -3.19592924e+02  8.37189631e+02 -1.09294990e+03\n",
      "  6.72509140e+03 -3.92029312e+03  5.23481504e+03 -2.86773438e+03\n",
      "  2.74318639e+03 -3.85590937e+03  1.35995900e+03 -1.35203302e+03\n",
      "  1.61749364e+04 -3.19147935e+03 -1.72292495e+03 -2.04287745e+03\n",
      "  3.03272583e+03  2.25580485e+03 -8.03911213e+02 -1.70529605e+03\n",
      "  3.06963510e+03  8.30296886e+03  3.84447040e+03 -1.42152641e+03\n",
      "  7.81819658e+03 -9.25782795e+02 -1.55530766e+03 -1.01422502e+03\n",
      " -7.69358805e+02 -1.04815537e+03 -2.46188167e+03 -4.99227613e+02\n",
      " -1.46857583e+03 -5.42898430e+03 -5.12283766e+02  2.59508906e+02\n",
      " -3.50016302e+03 -8.73337892e+02  2.88994806e+03 -1.19156883e+02\n",
      "  2.39001042e+03 -3.33967387e+03 -4.51034166e+03 -1.85187103e+02\n",
      " -3.92851443e+03  1.50788082e+03  2.40124010e+03 -5.18564942e+03\n",
      " -3.14040687e+03 -2.39484521e+03  2.32023428e+03  5.12714865e+03\n",
      " -3.61929029e+03  2.62120390e+03 -2.38440808e+03 -3.80310239e+03\n",
      " -2.39722189e+03 -3.15296744e+03 -4.30890844e+03  1.24548248e+04\n",
      "  1.21104827e+04 -2.95194950e+02 -3.96714350e+03  8.27308743e+03\n",
      " -2.04985923e+03  2.68938096e+03  1.62152102e+02 -6.33594409e+01]\n",
      "Mean Absolute Percentage Error on test set: 108.70188209463059\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class LassoCoordinateDescent:\n",
    "    def __init__(self, lambda_=0.1, max_iter=1000, tol=1e-4):\n",
    "        self.lambda_ = lambda_\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.coef_ = None\n",
    "        self.scaler_ = None\n",
    "    \n",
    "    def soft_thresholding(self, rho, lambda_):\n",
    "        if rho < -lambda_:\n",
    "            return rho + lambda_\n",
    "        elif rho > lambda_:\n",
    "            return rho - lambda_\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Standardize the features\n",
    "        self.scaler_ = StandardScaler()\n",
    "        X_scaled = self.scaler_.fit_transform(X)\n",
    "        \n",
    "        # Initialize coefficients\n",
    "        n, d = X_scaled.shape\n",
    "        self.coef_ = np.zeros(d)\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            coef_old = self.coef_.copy()\n",
    "            \n",
    "            for j in range(d):\n",
    "                X_j = X_scaled[:, j]\n",
    "                residual = y - X_scaled @ self.coef_ + self.coef_[j] * X_j\n",
    "                rho = X_j.T @ residual\n",
    "                \n",
    "                # Update coefficient for feature j using soft-thresholding\n",
    "                self.coef_[j] = self.soft_thresholding(rho / (X_j.T @ X_j), self.lambda_)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.max(np.abs(self.coef_ - coef_old)) < self.tol:\n",
    "                print(f'Converged after {iteration} iterations.')\n",
    "                break\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Standardize the test data using the scaler fitted on training data\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "        \n",
    "        # Compute predictions\n",
    "        return X_scaled @ self.coef_\n",
    "\n",
    "    def mean_absolute_percentage_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Percentage Error (MAPE)\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Compute the MAPE on the test set\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        return self.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Assume you've split your data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# Create a Lasso model\n",
    "lambda_ = 0.1  # Regularization strength\n",
    "lasso = LassoCoordinateDescent(lambda_=lambda_)\n",
    "\n",
    "# Fit the model to the training data\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lasso.predict(X_test)\n",
    "print('Predicted prices:', y_pred)\n",
    "\n",
    "# Evaluate the model using MAPE\n",
    "mape = lasso.score(X_test, y_test)\n",
    "print('Mean Absolute Percentage Error on test set:', mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted prices: [ 8.37559741e+02 -2.09063528e+03 -5.98709753e+02 -2.02548063e+03\n",
      " -7.96529378e+02 -3.22158228e+03 -2.26852891e+03 -2.56636204e+03\n",
      "  3.14847864e+03  2.31375190e+03 -1.68482343e+03 -1.55961740e+03\n",
      "  2.06708689e+03  2.56814825e+03 -1.30725298e+03 -2.06008173e+03\n",
      "  1.71476123e+03  6.97223887e+03 -3.95470251e+03 -1.73000559e+03\n",
      "  1.84794725e+03  7.02289323e+03 -3.06169172e+03 -4.01301002e+01\n",
      " -3.08801976e+03  5.16901841e+03 -8.04609644e+02 -3.97531951e+03\n",
      "  5.02035263e+03  3.72046906e+03 -2.90069380e+03 -1.03103394e+03\n",
      " -2.43435008e+03 -8.81852393e+02 -6.58965723e+02 -2.99991457e+03\n",
      " -2.15037311e+03 -1.01782778e+03  5.69807036e+03 -1.68758536e+03\n",
      " -1.02779830e+03 -1.39215889e+03 -3.11574600e+03 -5.36103271e+03\n",
      " -3.58333177e+03  6.13216392e+03 -1.55192940e+03 -3.14506992e+02\n",
      " -1.51934717e+03  2.74766461e+03  2.22404014e+03 -3.97974964e+03\n",
      "  4.09815979e+03  5.43720385e+03 -4.67389789e+03 -3.34066875e+03\n",
      " -5.42444853e+02 -2.05779618e+02  5.17678466e+03  5.54103433e+03\n",
      "  1.51192938e+03 -1.96916958e+03 -3.26439895e+03  2.55765877e+02\n",
      "  2.46775691e+03 -2.19917509e+03  3.44945548e+03 -3.72351029e+03\n",
      " -2.94369634e+03 -5.26363526e+01  6.82674252e+03 -4.62322267e+00\n",
      "  2.18148170e+03 -3.49531745e+03  7.91499816e+03  2.90089518e+03\n",
      " -1.78963860e+03 -3.65673031e+03 -4.23581073e+02 -1.71405559e+03\n",
      " -7.03416632e+02 -2.45950384e+03 -6.70287942e+02 -1.18880736e+02\n",
      " -2.75899282e+03 -4.22051431e+03  3.04205984e+02  2.17463981e+03\n",
      " -1.40999526e+03 -7.55980245e+01 -2.35596751e+03 -3.90354698e+03\n",
      " -4.19172487e+02 -6.81768950e+01  1.89590271e+03 -1.77752937e+03\n",
      "  1.14591105e+04 -3.05218684e+03  3.30382075e+03 -1.85011690e+03\n",
      "  6.64764974e+01 -1.22375814e+03 -3.22374575e+02  6.12091757e+03\n",
      " -1.99746648e+03 -3.48515105e+03  6.13295317e+03 -2.48996040e+03\n",
      " -1.20670406e+03 -1.35127330e+03  8.40075204e+02  6.21518413e+02\n",
      " -1.04067674e+03  3.02105092e+03 -1.54405484e+03 -2.29272062e+03\n",
      " -4.01461921e+03  2.62347401e+03  1.69306063e+03  3.01738621e+03\n",
      " -3.27302373e+03 -3.10202082e+03 -2.01822277e+03  4.46009644e+03\n",
      "  1.13839906e+03 -1.24689698e+03  2.69302549e+03 -9.56259172e+02\n",
      " -2.56166236e+03  2.66260546e+03  1.41631672e+02  4.92423194e+03\n",
      " -2.71003941e+02 -8.58130356e+02 -3.89290636e+03 -1.35801949e+03\n",
      "  1.17779309e+02  7.78201754e+02 -2.63988324e+03 -6.03626358e+03\n",
      "  1.53636799e+03 -6.24835949e+02  1.41987345e+03 -2.61984913e+03\n",
      "  1.36459110e+03  5.43734257e+02 -4.12226910e+03 -2.32539125e+03\n",
      " -2.93805639e+03  8.53433902e+02 -5.85709696e+02  5.09162160e+03\n",
      " -1.79030020e+03 -1.71913075e+03  3.63440856e+02  1.81169168e+02\n",
      " -2.38492755e+03  2.39047319e+03  7.82492878e+01  8.71500549e+03\n",
      "  5.49563966e+02  5.17507500e+03  4.67553326e+03 -3.33431604e+03\n",
      " -2.04488852e+03  2.00833531e+03 -3.00089033e+03  2.65150076e+03\n",
      " -1.82914989e+03 -2.83294418e+03 -2.20781925e+03  1.42024670e+03\n",
      " -1.64422110e+03  2.02361198e+03 -7.88525739e+01 -9.64521131e+02\n",
      "  6.12299351e+03 -3.37593080e+02 -1.19930172e+03 -2.68219236e+02\n",
      "  1.44726703e+03  2.26091403e+02  2.86847031e+03 -3.19128020e+03\n",
      " -1.90273389e+03 -3.39351868e+03 -4.49269431e+03 -2.07790873e+03\n",
      " -1.39499904e+03 -6.00387147e+02 -1.70206444e+03 -3.55410174e+03\n",
      " -5.21380900e+03  6.68785086e+02 -4.60756000e+02 -2.21388244e+01\n",
      " -4.17610132e+03 -3.21056955e+03 -6.06964958e+02  6.79654347e+03\n",
      " -8.91197076e+02 -2.65986968e+03 -3.43931062e+03 -2.37147866e+03\n",
      "  5.15262738e+03  6.58315426e+03 -4.56188814e+02 -9.60051946e+02\n",
      "  1.12377077e+02 -1.24340881e+03 -2.05899353e+03  2.69408550e+02\n",
      " -1.00235061e+03 -7.21119621e+02 -4.28536956e+03  8.23466919e+02\n",
      " -2.54150644e+03 -1.73085956e+03 -3.04655712e+03  5.55329438e+02\n",
      " -1.64371129e+03 -3.19821413e+02  8.35589427e+02 -1.09415626e+03\n",
      "  6.72131498e+03 -3.91852358e+03  5.23242243e+03 -2.86567128e+03\n",
      "  2.74166162e+03 -3.85404901e+03  1.35830547e+03 -1.35066643e+03\n",
      "  1.61710901e+04 -3.18907306e+03 -1.72250174e+03 -2.04195926e+03\n",
      "  3.03108769e+03  2.25417030e+03 -8.02783816e+02 -1.70425592e+03\n",
      "  3.06785733e+03  8.29840751e+03  3.84223070e+03 -1.42062212e+03\n",
      "  7.81490427e+03 -9.25881015e+02 -1.55360024e+03 -1.01369875e+03\n",
      " -7.67695048e+02 -1.04685490e+03 -2.46030418e+03 -4.98470691e+02\n",
      " -1.46766432e+03 -5.42806568e+03 -5.11990431e+02  2.58921125e+02\n",
      " -3.49741192e+03 -8.72848677e+02  2.88832335e+03 -1.20164425e+02\n",
      "  2.38881694e+03 -3.33738867e+03 -4.50847936e+03 -1.84514303e+02\n",
      " -3.92637566e+03  1.50833798e+03  2.39952680e+03 -5.18439944e+03\n",
      " -3.14025481e+03 -2.39420713e+03  2.31879762e+03  5.12493511e+03\n",
      " -3.61680018e+03  2.61941709e+03 -2.38175485e+03 -3.80083037e+03\n",
      " -2.39474791e+03 -3.15067852e+03 -4.30741057e+03  1.24551678e+04\n",
      "  1.21064734e+04 -2.95371287e+02 -3.96578347e+03  8.26851528e+03\n",
      " -2.04787287e+03  2.68790303e+03  1.65120324e+02 -6.27955890e+01]\n",
      "Mean Squared Error on test set: 117166908.03509988\n",
      "Mean Absolute Percentage Error on test set: 108.6973440293855\n"
     ]
    }
   ],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, lambda_=1.0):\n",
    "        self.lambda_ = lambda_  # Regularization strength\n",
    "        self.coef_ = None\n",
    "        self.scaler_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Standardize the features\n",
    "        self.scaler_ = StandardScaler()\n",
    "        X_scaled = self.scaler_.fit_transform(X)\n",
    "        \n",
    "        # Solve the normal equation (X'X + lambda*I) * beta = X'y\n",
    "        n, d = X_scaled.shape\n",
    "        I = np.eye(d)  # Identity matrix of size d\n",
    "        XTX = X_scaled.T @ X_scaled\n",
    "        XTy = X_scaled.T @ y\n",
    "        \n",
    "        # Solve for beta (ridge coefficients)\n",
    "        self.coef_ = np.linalg.solve(XTX + self.lambda_ * I, XTy)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Standardize the test data using the same scaler as training data\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "        \n",
    "        # Compute predictions\n",
    "        return X_scaled @ self.coef_\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Compute the Mean Squared Error on the test set\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        return np.mean((y_test - y_pred) ** 2)\n",
    "\n",
    "    def mean_absolute_percentage_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Percentage Error (MAPE)\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Create a Ridge regression model\n",
    "ridge = RidgeRegression(lambda_=1.0)\n",
    "\n",
    "# Fit the model\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge.predict(X_test)\n",
    "print('Predicted prices:', y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = ridge.score(X_test, y_test)\n",
    "print('Mean Squared Error on test set:', mse)\n",
    "\n",
    "# Evaluate using MAPE\n",
    "mape = ridge.mean_absolute_percentage_error(y_test, y_pred)\n",
    "print('Mean Absolute Percentage Error on test set:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Ridge Coefficients:\n",
      " [ -927.87484004  1050.44594184 -2211.42339228]\n",
      "Sklearn Ridge Coefficients:\n",
      " [ -927.87484004  1050.44594184 -2211.42339228]\n",
      "Custom Ridge Predictions:\n",
      " [ 8.37559741e+02 -2.09063528e+03 -5.98709753e+02 -2.02548063e+03\n",
      " -7.96529378e+02 -3.22158228e+03 -2.26852891e+03 -2.56636204e+03\n",
      "  3.14847864e+03  2.31375190e+03 -1.68482343e+03 -1.55961740e+03\n",
      "  2.06708689e+03  2.56814825e+03 -1.30725298e+03 -2.06008173e+03\n",
      "  1.71476123e+03  6.97223887e+03 -3.95470251e+03 -1.73000559e+03\n",
      "  1.84794725e+03  7.02289323e+03 -3.06169172e+03 -4.01301002e+01\n",
      " -3.08801976e+03  5.16901841e+03 -8.04609644e+02 -3.97531951e+03\n",
      "  5.02035263e+03  3.72046906e+03 -2.90069380e+03 -1.03103394e+03\n",
      " -2.43435008e+03 -8.81852393e+02 -6.58965723e+02 -2.99991457e+03\n",
      " -2.15037311e+03 -1.01782778e+03  5.69807036e+03 -1.68758536e+03\n",
      " -1.02779830e+03 -1.39215889e+03 -3.11574600e+03 -5.36103271e+03\n",
      " -3.58333177e+03  6.13216392e+03 -1.55192940e+03 -3.14506992e+02\n",
      " -1.51934717e+03  2.74766461e+03  2.22404014e+03 -3.97974964e+03\n",
      "  4.09815979e+03  5.43720385e+03 -4.67389789e+03 -3.34066875e+03\n",
      " -5.42444853e+02 -2.05779618e+02  5.17678466e+03  5.54103433e+03\n",
      "  1.51192938e+03 -1.96916958e+03 -3.26439895e+03  2.55765877e+02\n",
      "  2.46775691e+03 -2.19917509e+03  3.44945548e+03 -3.72351029e+03\n",
      " -2.94369634e+03 -5.26363526e+01  6.82674252e+03 -4.62322267e+00\n",
      "  2.18148170e+03 -3.49531745e+03  7.91499816e+03  2.90089518e+03\n",
      " -1.78963860e+03 -3.65673031e+03 -4.23581073e+02 -1.71405559e+03\n",
      " -7.03416632e+02 -2.45950384e+03 -6.70287942e+02 -1.18880736e+02\n",
      " -2.75899282e+03 -4.22051431e+03  3.04205984e+02  2.17463981e+03\n",
      " -1.40999526e+03 -7.55980245e+01 -2.35596751e+03 -3.90354698e+03\n",
      " -4.19172487e+02 -6.81768950e+01  1.89590271e+03 -1.77752937e+03\n",
      "  1.14591105e+04 -3.05218684e+03  3.30382075e+03 -1.85011690e+03\n",
      "  6.64764974e+01 -1.22375814e+03 -3.22374575e+02  6.12091757e+03\n",
      " -1.99746648e+03 -3.48515105e+03  6.13295317e+03 -2.48996040e+03\n",
      " -1.20670406e+03 -1.35127330e+03  8.40075204e+02  6.21518413e+02\n",
      " -1.04067674e+03  3.02105092e+03 -1.54405484e+03 -2.29272062e+03\n",
      " -4.01461921e+03  2.62347401e+03  1.69306063e+03  3.01738621e+03\n",
      " -3.27302373e+03 -3.10202082e+03 -2.01822277e+03  4.46009644e+03\n",
      "  1.13839906e+03 -1.24689698e+03  2.69302549e+03 -9.56259172e+02\n",
      " -2.56166236e+03  2.66260546e+03  1.41631672e+02  4.92423194e+03\n",
      " -2.71003941e+02 -8.58130356e+02 -3.89290636e+03 -1.35801949e+03\n",
      "  1.17779309e+02  7.78201754e+02 -2.63988324e+03 -6.03626358e+03\n",
      "  1.53636799e+03 -6.24835949e+02  1.41987345e+03 -2.61984913e+03\n",
      "  1.36459110e+03  5.43734257e+02 -4.12226910e+03 -2.32539125e+03\n",
      " -2.93805639e+03  8.53433902e+02 -5.85709696e+02  5.09162160e+03\n",
      " -1.79030020e+03 -1.71913075e+03  3.63440856e+02  1.81169168e+02\n",
      " -2.38492755e+03  2.39047319e+03  7.82492878e+01  8.71500549e+03\n",
      "  5.49563966e+02  5.17507500e+03  4.67553326e+03 -3.33431604e+03\n",
      " -2.04488852e+03  2.00833531e+03 -3.00089033e+03  2.65150076e+03\n",
      " -1.82914989e+03 -2.83294418e+03 -2.20781925e+03  1.42024670e+03\n",
      " -1.64422110e+03  2.02361198e+03 -7.88525739e+01 -9.64521131e+02\n",
      "  6.12299351e+03 -3.37593080e+02 -1.19930172e+03 -2.68219236e+02\n",
      "  1.44726703e+03  2.26091403e+02  2.86847031e+03 -3.19128020e+03\n",
      " -1.90273389e+03 -3.39351868e+03 -4.49269431e+03 -2.07790873e+03\n",
      " -1.39499904e+03 -6.00387147e+02 -1.70206444e+03 -3.55410174e+03\n",
      " -5.21380900e+03  6.68785086e+02 -4.60756000e+02 -2.21388244e+01\n",
      " -4.17610132e+03 -3.21056955e+03 -6.06964958e+02  6.79654347e+03\n",
      " -8.91197076e+02 -2.65986968e+03 -3.43931062e+03 -2.37147866e+03\n",
      "  5.15262738e+03  6.58315426e+03 -4.56188814e+02 -9.60051946e+02\n",
      "  1.12377077e+02 -1.24340881e+03 -2.05899353e+03  2.69408550e+02\n",
      " -1.00235061e+03 -7.21119621e+02 -4.28536956e+03  8.23466919e+02\n",
      " -2.54150644e+03 -1.73085956e+03 -3.04655712e+03  5.55329438e+02\n",
      " -1.64371129e+03 -3.19821413e+02  8.35589427e+02 -1.09415626e+03\n",
      "  6.72131498e+03 -3.91852358e+03  5.23242243e+03 -2.86567128e+03\n",
      "  2.74166162e+03 -3.85404901e+03  1.35830547e+03 -1.35066643e+03\n",
      "  1.61710901e+04 -3.18907306e+03 -1.72250174e+03 -2.04195926e+03\n",
      "  3.03108769e+03  2.25417030e+03 -8.02783816e+02 -1.70425592e+03\n",
      "  3.06785733e+03  8.29840751e+03  3.84223070e+03 -1.42062212e+03\n",
      "  7.81490427e+03 -9.25881015e+02 -1.55360024e+03 -1.01369875e+03\n",
      " -7.67695048e+02 -1.04685490e+03 -2.46030418e+03 -4.98470691e+02\n",
      " -1.46766432e+03 -5.42806568e+03 -5.11990431e+02  2.58921125e+02\n",
      " -3.49741192e+03 -8.72848677e+02  2.88832335e+03 -1.20164425e+02\n",
      "  2.38881694e+03 -3.33738867e+03 -4.50847936e+03 -1.84514303e+02\n",
      " -3.92637566e+03  1.50833798e+03  2.39952680e+03 -5.18439944e+03\n",
      " -3.14025481e+03 -2.39420713e+03  2.31879762e+03  5.12493511e+03\n",
      " -3.61680018e+03  2.61941709e+03 -2.38175485e+03 -3.80083037e+03\n",
      " -2.39474791e+03 -3.15067852e+03 -4.30741057e+03  1.24551678e+04\n",
      "  1.21064734e+04 -2.95371287e+02 -3.96578347e+03  8.26851528e+03\n",
      " -2.04787287e+03  2.68790303e+03  1.65120324e+02 -6.27955890e+01]\n",
      "Sklearn Ridge Predictions:\n",
      " [ 8.37559741e+02 -2.09063528e+03 -5.98709753e+02 -2.02548063e+03\n",
      " -7.96529378e+02 -3.22158228e+03 -2.26852891e+03 -2.56636204e+03\n",
      "  3.14847864e+03  2.31375190e+03 -1.68482343e+03 -1.55961740e+03\n",
      "  2.06708689e+03  2.56814825e+03 -1.30725298e+03 -2.06008173e+03\n",
      "  1.71476123e+03  6.97223887e+03 -3.95470251e+03 -1.73000559e+03\n",
      "  1.84794725e+03  7.02289323e+03 -3.06169172e+03 -4.01301002e+01\n",
      " -3.08801976e+03  5.16901841e+03 -8.04609644e+02 -3.97531951e+03\n",
      "  5.02035263e+03  3.72046906e+03 -2.90069380e+03 -1.03103394e+03\n",
      " -2.43435008e+03 -8.81852393e+02 -6.58965723e+02 -2.99991457e+03\n",
      " -2.15037311e+03 -1.01782778e+03  5.69807036e+03 -1.68758536e+03\n",
      " -1.02779830e+03 -1.39215889e+03 -3.11574600e+03 -5.36103271e+03\n",
      " -3.58333177e+03  6.13216392e+03 -1.55192940e+03 -3.14506992e+02\n",
      " -1.51934717e+03  2.74766461e+03  2.22404014e+03 -3.97974964e+03\n",
      "  4.09815979e+03  5.43720385e+03 -4.67389789e+03 -3.34066875e+03\n",
      " -5.42444853e+02 -2.05779618e+02  5.17678466e+03  5.54103433e+03\n",
      "  1.51192938e+03 -1.96916958e+03 -3.26439895e+03  2.55765877e+02\n",
      "  2.46775691e+03 -2.19917509e+03  3.44945548e+03 -3.72351029e+03\n",
      " -2.94369634e+03 -5.26363526e+01  6.82674252e+03 -4.62322267e+00\n",
      "  2.18148170e+03 -3.49531745e+03  7.91499816e+03  2.90089518e+03\n",
      " -1.78963860e+03 -3.65673031e+03 -4.23581073e+02 -1.71405559e+03\n",
      " -7.03416632e+02 -2.45950384e+03 -6.70287942e+02 -1.18880736e+02\n",
      " -2.75899282e+03 -4.22051431e+03  3.04205984e+02  2.17463981e+03\n",
      " -1.40999526e+03 -7.55980245e+01 -2.35596751e+03 -3.90354698e+03\n",
      " -4.19172487e+02 -6.81768950e+01  1.89590271e+03 -1.77752937e+03\n",
      "  1.14591105e+04 -3.05218684e+03  3.30382075e+03 -1.85011690e+03\n",
      "  6.64764974e+01 -1.22375814e+03 -3.22374575e+02  6.12091757e+03\n",
      " -1.99746648e+03 -3.48515105e+03  6.13295317e+03 -2.48996040e+03\n",
      " -1.20670406e+03 -1.35127330e+03  8.40075204e+02  6.21518413e+02\n",
      " -1.04067674e+03  3.02105092e+03 -1.54405484e+03 -2.29272062e+03\n",
      " -4.01461921e+03  2.62347401e+03  1.69306063e+03  3.01738621e+03\n",
      " -3.27302373e+03 -3.10202082e+03 -2.01822277e+03  4.46009644e+03\n",
      "  1.13839906e+03 -1.24689698e+03  2.69302549e+03 -9.56259172e+02\n",
      " -2.56166236e+03  2.66260546e+03  1.41631672e+02  4.92423194e+03\n",
      " -2.71003941e+02 -8.58130356e+02 -3.89290636e+03 -1.35801949e+03\n",
      "  1.17779309e+02  7.78201754e+02 -2.63988324e+03 -6.03626358e+03\n",
      "  1.53636799e+03 -6.24835949e+02  1.41987345e+03 -2.61984913e+03\n",
      "  1.36459110e+03  5.43734257e+02 -4.12226910e+03 -2.32539125e+03\n",
      " -2.93805639e+03  8.53433902e+02 -5.85709696e+02  5.09162160e+03\n",
      " -1.79030020e+03 -1.71913075e+03  3.63440856e+02  1.81169168e+02\n",
      " -2.38492755e+03  2.39047319e+03  7.82492878e+01  8.71500549e+03\n",
      "  5.49563966e+02  5.17507500e+03  4.67553326e+03 -3.33431604e+03\n",
      " -2.04488852e+03  2.00833531e+03 -3.00089033e+03  2.65150076e+03\n",
      " -1.82914989e+03 -2.83294418e+03 -2.20781925e+03  1.42024670e+03\n",
      " -1.64422110e+03  2.02361198e+03 -7.88525739e+01 -9.64521131e+02\n",
      "  6.12299351e+03 -3.37593080e+02 -1.19930172e+03 -2.68219236e+02\n",
      "  1.44726703e+03  2.26091403e+02  2.86847031e+03 -3.19128020e+03\n",
      " -1.90273389e+03 -3.39351868e+03 -4.49269431e+03 -2.07790873e+03\n",
      " -1.39499904e+03 -6.00387147e+02 -1.70206444e+03 -3.55410174e+03\n",
      " -5.21380900e+03  6.68785086e+02 -4.60756000e+02 -2.21388244e+01\n",
      " -4.17610132e+03 -3.21056955e+03 -6.06964958e+02  6.79654347e+03\n",
      " -8.91197076e+02 -2.65986968e+03 -3.43931062e+03 -2.37147866e+03\n",
      "  5.15262738e+03  6.58315426e+03 -4.56188814e+02 -9.60051946e+02\n",
      "  1.12377077e+02 -1.24340881e+03 -2.05899353e+03  2.69408550e+02\n",
      " -1.00235061e+03 -7.21119621e+02 -4.28536956e+03  8.23466919e+02\n",
      " -2.54150644e+03 -1.73085956e+03 -3.04655712e+03  5.55329438e+02\n",
      " -1.64371129e+03 -3.19821413e+02  8.35589427e+02 -1.09415626e+03\n",
      "  6.72131498e+03 -3.91852358e+03  5.23242243e+03 -2.86567128e+03\n",
      "  2.74166162e+03 -3.85404901e+03  1.35830547e+03 -1.35066643e+03\n",
      "  1.61710901e+04 -3.18907306e+03 -1.72250174e+03 -2.04195926e+03\n",
      "  3.03108769e+03  2.25417030e+03 -8.02783816e+02 -1.70425592e+03\n",
      "  3.06785733e+03  8.29840751e+03  3.84223070e+03 -1.42062212e+03\n",
      "  7.81490427e+03 -9.25881015e+02 -1.55360024e+03 -1.01369875e+03\n",
      " -7.67695048e+02 -1.04685490e+03 -2.46030418e+03 -4.98470691e+02\n",
      " -1.46766432e+03 -5.42806568e+03 -5.11990431e+02  2.58921125e+02\n",
      " -3.49741192e+03 -8.72848677e+02  2.88832335e+03 -1.20164425e+02\n",
      "  2.38881694e+03 -3.33738867e+03 -4.50847936e+03 -1.84514303e+02\n",
      " -3.92637566e+03  1.50833798e+03  2.39952680e+03 -5.18439944e+03\n",
      " -3.14025481e+03 -2.39420713e+03  2.31879762e+03  5.12493511e+03\n",
      " -3.61680018e+03  2.61941709e+03 -2.38175485e+03 -3.80083037e+03\n",
      " -2.39474791e+03 -3.15067852e+03 -4.30741057e+03  1.24551678e+04\n",
      "  1.21064734e+04 -2.95371287e+02 -3.96578347e+03  8.26851528e+03\n",
      " -2.04787287e+03  2.68790303e+03  1.65120324e+02 -6.27955890e+01]\n",
      "Custom Ridge Mape: 1.0869734402938551\n",
      "Sklearn Ridge Mape: 1.0869734402938551\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Custom Ridge Regression implementation\n",
    "ridge_custom = RidgeRegression(lambda_=1.0)\n",
    "ridge_custom.fit(X_train, y_train)\n",
    "beta_custom = ridge_custom.coef_\n",
    "\n",
    "# Sklearn Ridge Regression\n",
    "ridge_sklearn = SklearnRidge(alpha=1.0, fit_intercept=False)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "ridge_sklearn.fit(X_train_scaled, y_train)\n",
    "beta_sklearn = ridge_sklearn.coef_\n",
    "\n",
    "# Compare coefficients\n",
    "print('Custom Ridge Coefficients:\\n', beta_custom)\n",
    "print('Sklearn Ridge Coefficients:\\n', beta_sklearn)\n",
    "\n",
    "# Predictions and comparison\n",
    "y_pred_custom = ridge_custom.predict(X_test)\n",
    "y_pred_sklearn = ridge_sklearn.predict(scaler.transform(X_test))\n",
    "\n",
    "# Compare predictions\n",
    "print('Custom Ridge Predictions:\\n', y_pred_custom)\n",
    "print('Sklearn Ridge Predictions:\\n', y_pred_sklearn)\n",
    "\n",
    "# Evaluate both models (MSE)\n",
    "mape_custom = mean_absolute_percentage_error(y_test, y_pred_custom)\n",
    "mape_sklearn = mean_absolute_percentage_error(y_test, y_pred_sklearn)\n",
    "\n",
    "print('Custom Ridge Mape:', mape_custom)\n",
    "print('Sklearn Ridge Mape:', mape_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE ridge gd: 108.69660491352622\n",
      "Coefficients: [ -940.75439835  1062.45985747 -2193.66964844]\n"
     ]
    }
   ],
   "source": [
    "class RidgeGradientDescent:\n",
    "    def __init__(self, lambda_=1.0, alpha=0.01, max_iter=1000, tol=1e-6):\n",
    "        self.lambda_ = lambda_  # Regularization strength\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.max_iter = max_iter  # Maximum number of iterations\n",
    "        self.tol = tol  # Tolerance for stopping criterion\n",
    "        self.coef_ = None  # Coefficients (beta)\n",
    "        self.scaler_ = None  # For feature scaling\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Standardize the features\n",
    "        self.scaler_ = StandardScaler()\n",
    "        X_scaled = self.scaler_.fit_transform(X)\n",
    "        \n",
    "        n, d = X_scaled.shape\n",
    "        self.coef_ = np.zeros(d)  # Initialize coefficients\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            # Compute predictions\n",
    "            y_pred = X_scaled @ self.coef_\n",
    "            \n",
    "            # Compute the gradient\n",
    "            gradient = -(X_scaled.T @ (y - y_pred)) / n + (self.lambda_ / n) * self.coef_\n",
    "            \n",
    "            # Update coefficients (gradient descent step)\n",
    "            self.coef_ -= self.alpha * gradient\n",
    "            \n",
    "            # Check convergence (if the norm of the gradient is small enough)\n",
    "            if np.linalg.norm(gradient, ord=2) < self.tol:\n",
    "                print(f'Converged after {iteration} iterations.')\n",
    "                break\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Standardize the test data using the same scaler as training data\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "        return X_scaled @ self.coef_\n",
    "\n",
    "    def mean_absolute_percentage_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Percentage Error (MAPE)\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        # Compute predictions and MAPE\n",
    "        y_pred = self.predict(X_test)\n",
    "        return self.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Create the Ridge Regression model using Gradient Descent\n",
    "ridge_gd = RidgeGradientDescent(lambda_=1.0, alpha=0.01, max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "ridge_gd.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_gd = ridge_gd.predict(X_test)\n",
    "\n",
    "mape_gd = ridge_gd.score(X_test, y_test)\n",
    "print(f'MAPE ridge gd: {mape_gd}')\n",
    "print(f'Coefficients: {ridge_gd.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set MAPE: 9.61%\n",
      "Test set MAPE: 9.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the MLPRegressor model\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 50),  # Two hidden layers with 100 and 50 neurons\n",
    "                   activation='relu',  # Activation function\n",
    "                   solver='adam',  # Optimization method\n",
    "                   max_iter=500,  # Maximum number of iterations\n",
    "                   random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred = mlp.predict(X_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using MAPE on both train and test sets\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_train_pred) * 100\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_test_pred) * 100\n",
    "\n",
    "print(f'Train set MAPE: {mape_train:.2f}%')\n",
    "print(f'Test set MAPE: {mape_test:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mape of 8% for random forest vs 9.5% for mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
