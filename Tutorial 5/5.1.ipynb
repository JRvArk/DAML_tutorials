{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge as SklearnRidge\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../ToyotaCorolla.csv\")\n",
    "df = df.drop(columns=['Id', 'Model', 'Mfg_Month', 'Mfg_Year', 'Cylinders'])\n",
    "df['Fuel_Type'] = df['Fuel_Type'].astype('category')\n",
    "df['Color'] = df['Color'].astype('category')\n",
    "# df['Gears'] = df['Gears'].astype('category')\n",
    "# df['Doors'] = df['Doors'].astype('category')\n",
    "\n",
    "df.loc[df['CC'] == 16000, 'CC'] = 1600\n",
    "df.rename(columns={'Age_08_04': 'Age'}, inplace=True)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() == 2:\n",
    "        df[col] = df[col].astype('bool')\n",
    "\n",
    "df['Combined_Color'] = df.apply(\n",
    "    lambda row:\n",
    "    f'Met_{row[\"Color\"]}' if row['Met_Color']\n",
    "    else row['Color'], axis=1\n",
    ").astype('category')\n",
    "\n",
    "df['Age^2'] = df['Age']**2\n",
    "df['KM^2'] = df['KM']**2\n",
    "df['eAge'] = np.exp(-df['Age'])\n",
    "df['eKM'] = np.exp(-df['KM'])\n",
    "df['Weight^2'] = df['Weight'] ** 2\n",
    "\n",
    "features = ['Sport_Model', 'Fuel_Type', 'CC', 'Gears', 'Weight', 'HP', 'KM', 'KM^2', 'eKM', 'Age', 'Age^2', 'eAge',\n",
    "            'Quarterly_Tax', 'Guarantee_Period']\n",
    "extras = ['Automatic', 'ABS', 'Airbag_1', 'Airbag_2', 'Airco', 'Automatic_airco', 'Boardcomputer', 'CD_Player', 'Central_Lock',\n",
    "          'Powered_Windows', 'Power_Steering', 'Radio', 'Mistlamps', 'Backseat_Divider', 'Metallic_Rim', 'Radio_cassette', \n",
    "          'Parking_Assistant', 'Tow_Bar', 'Combined_Color', 'Mfr_Guarantee', 'BOVAG_Guarantee']\n",
    "features.extend(extras)\n",
    "\n",
    "cat_features = list(set(df.select_dtypes('category').columns).intersection(set(features)))\n",
    "num_features = list(set(df.select_dtypes('number').columns).intersection(set(features)))\n",
    "bool_features = list(set(df.select_dtypes('bool').columns).intersection(set(features)))\n",
    "\n",
    "X = df[num_features].copy()\n",
    "y = df['Price']\n",
    "\n",
    "# X = pd.get_dummies(X)\n",
    "# X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, shuffle=True, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>5.594708e+01</td>\n",
       "      <td>1.859999e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>6.100000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>8.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guarantee_Period</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>3.815460e+00</td>\n",
       "      <td>3.011025e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age^2</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>3.475794e+03</td>\n",
       "      <td>1.836373e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.936000e+03</td>\n",
       "      <td>3.721000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>6.400000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eKM</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>2.049468e-03</td>\n",
       "      <td>2.739122e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.678794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>1.566828e+03</td>\n",
       "      <td>1.871824e+02</td>\n",
       "      <td>1.300000e+03</td>\n",
       "      <td>1.400000e+03</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>1.015021e+02</td>\n",
       "      <td>1.498108e+01</td>\n",
       "      <td>6.900000e+01</td>\n",
       "      <td>9.000000e+01</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>1.920000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KM^2</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>6.102562e+09</td>\n",
       "      <td>6.954814e+09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.849000e+09</td>\n",
       "      <td>4.018232e+09</td>\n",
       "      <td>7.572612e+09</td>\n",
       "      <td>5.904900e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gears</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>5.026462e+00</td>\n",
       "      <td>1.885104e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>1.072460e+03</td>\n",
       "      <td>5.264112e+01</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.040000e+03</td>\n",
       "      <td>1.070000e+03</td>\n",
       "      <td>1.085000e+03</td>\n",
       "      <td>1.615000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KM</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>6.853326e+04</td>\n",
       "      <td>3.750645e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.300000e+04</td>\n",
       "      <td>6.338950e+04</td>\n",
       "      <td>8.702075e+04</td>\n",
       "      <td>2.430000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eAge</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>7.469766e-04</td>\n",
       "      <td>1.463894e-02</td>\n",
       "      <td>1.804851e-35</td>\n",
       "      <td>3.975450e-31</td>\n",
       "      <td>3.221340e-27</td>\n",
       "      <td>7.781132e-20</td>\n",
       "      <td>3.678794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>8.712256e+01</td>\n",
       "      <td>4.112861e+01</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>6.900000e+01</td>\n",
       "      <td>8.500000e+01</td>\n",
       "      <td>8.500000e+01</td>\n",
       "      <td>2.830000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count          mean           std           min  \\\n",
       "Age               1436.0  5.594708e+01  1.859999e+01  1.000000e+00   \n",
       "Guarantee_Period  1436.0  3.815460e+00  3.011025e+00  3.000000e+00   \n",
       "Age^2             1436.0  3.475794e+03  1.836373e+03  1.000000e+00   \n",
       "eKM               1436.0  2.049468e-03  2.739122e-02  0.000000e+00   \n",
       "CC                1436.0  1.566828e+03  1.871824e+02  1.300000e+03   \n",
       "HP                1436.0  1.015021e+02  1.498108e+01  6.900000e+01   \n",
       "KM^2              1436.0  6.102562e+09  6.954814e+09  1.000000e+00   \n",
       "Gears             1436.0  5.026462e+00  1.885104e-01  3.000000e+00   \n",
       "Weight            1436.0  1.072460e+03  5.264112e+01  1.000000e+03   \n",
       "KM                1436.0  6.853326e+04  3.750645e+04  1.000000e+00   \n",
       "eAge              1436.0  7.469766e-04  1.463894e-02  1.804851e-35   \n",
       "Quarterly_Tax     1436.0  8.712256e+01  4.112861e+01  1.900000e+01   \n",
       "\n",
       "                           25%           50%           75%           max  \n",
       "Age               4.400000e+01  6.100000e+01  7.000000e+01  8.000000e+01  \n",
       "Guarantee_Period  3.000000e+00  3.000000e+00  3.000000e+00  3.600000e+01  \n",
       "Age^2             1.936000e+03  3.721000e+03  4.900000e+03  6.400000e+03  \n",
       "eKM               0.000000e+00  0.000000e+00  0.000000e+00  3.678794e-01  \n",
       "CC                1.400000e+03  1.600000e+03  1.600000e+03  2.000000e+03  \n",
       "HP                9.000000e+01  1.100000e+02  1.100000e+02  1.920000e+02  \n",
       "KM^2              1.849000e+09  4.018232e+09  7.572612e+09  5.904900e+10  \n",
       "Gears             5.000000e+00  5.000000e+00  5.000000e+00  6.000000e+00  \n",
       "Weight            1.040000e+03  1.070000e+03  1.085000e+03  1.615000e+03  \n",
       "KM                4.300000e+04  6.338950e+04  8.702075e+04  2.430000e+05  \n",
       "eAge              3.975450e-31  3.221340e-27  7.781132e-20  3.678794e-01  \n",
       "Quarterly_Tax     6.900000e+01  8.500000e+01  8.500000e+01  2.830000e+02  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error on test set: 10.66361550830001\n"
     ]
    }
   ],
   "source": [
    "class LassoCoordinateDescent:\n",
    "    def __init__(self, lambda_=0.1, max_iter=1000, tol=1e-4, scaler=None):\n",
    "        self.lambda_ = lambda_\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.coef_ = None\n",
    "        if scaler == None:\n",
    "            self.scaler_ = StandardScaler()\n",
    "        else:\n",
    "            self.scaler_ = scaler\n",
    "    \n",
    "    def soft_thresholding(self, rho, lambda_):\n",
    "        if rho < -lambda_:\n",
    "            return rho + lambda_\n",
    "        elif rho > lambda_:\n",
    "            return rho - lambda_\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Standardize the features\n",
    "        # self.scaler_ = StandardScaler()\n",
    "        X_scaled = self.scaler_.fit_transform(X)\n",
    "        \n",
    "        # Initialize coefficients\n",
    "        n, d = X_scaled.shape\n",
    "        self.coef_ = np.zeros(d)\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            coef_old = self.coef_.copy()\n",
    "            \n",
    "            for j in range(d):\n",
    "                X_j = X_scaled[:, j]\n",
    "                residual = y - X_scaled @ self.coef_ + self.coef_[j] * X_j\n",
    "                rho = X_j.T @ residual\n",
    "                \n",
    "                # Update coefficient for feature j using soft-thresholding\n",
    "                self.coef_[j] = self.soft_thresholding(rho / (X_j.T @ X_j), self.lambda_)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.max(np.abs(self.coef_ - coef_old)) < self.tol:\n",
    "                print(f'Converged after {iteration} iterations.')\n",
    "                break\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Standardize the test data using the scaler fitted on training data\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "        \n",
    "        # Compute predictions\n",
    "        return X_scaled @ self.coef_\n",
    "\n",
    "    def mean_absolute_percentage_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Percentage Error (MAPE)\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Compute the MAPE on the test set\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        return self.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Create a Lasso model\n",
    "lambda_ = 0.1  # Regularization strength\n",
    "# The difference between MinMax and Standard is insane\n",
    "lasso = LassoCoordinateDescent(lambda_=lambda_, scaler=MinMaxScaler())\n",
    "\n",
    "# Fit the model to the training data\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lasso.predict(X_test)\n",
    "#print('Predicted prices:', y_pred)\n",
    "\n",
    "# Evaluate the model using MAPE\n",
    "mape = lasso.score(X_test, y_test)\n",
    "print('Mean Absolute Percentage Error on test set:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test set: 3151555.363609479\n",
      "Mean Absolute Percentage Error on test set: 10.619804484642712\n"
     ]
    }
   ],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, lambda_=1.0, scaler=None):\n",
    "        self.lambda_ = lambda_  # Regularization strength\n",
    "        self.coef_ = None\n",
    "        if scaler == None:\n",
    "            self.scaler_ = StandardScaler()\n",
    "        else:\n",
    "            self.scaler_ = scaler\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Standardize the features\n",
    "        #self.scaler_ = StandardScaler()\n",
    "        X_scaled = self.scaler_.fit_transform(X)\n",
    "        \n",
    "        # Solve the normal equation (X'X + lambda*I) * beta = X'y\n",
    "        n, d = X_scaled.shape\n",
    "        I = np.eye(d)  # Identity matrix of size d\n",
    "        XTX = X_scaled.T @ X_scaled\n",
    "        XTy = X_scaled.T @ y\n",
    "        \n",
    "        # Solve for beta (ridge coefficients)\n",
    "        self.coef_ = np.linalg.solve(XTX + self.lambda_ * I, XTy)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Standardize the test data using the same scaler as training data\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "        \n",
    "        # Compute predictions\n",
    "        return X_scaled @ self.coef_\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Compute the Mean Squared Error on the test set\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        return np.mean((y_test - y_pred) ** 2)\n",
    "\n",
    "    def mean_absolute_percentage_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Percentage Error (MAPE)\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Create a Ridge regression model\n",
    "ridge = RidgeRegression(lambda_=1.0, scaler=MinMaxScaler())\n",
    "\n",
    "# Fit the model\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge.predict(X_test)\n",
    "#print('Predicted prices:', y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = ridge.score(X_test, y_test)\n",
    "print('Mean Squared Error on test set:', mse)\n",
    "\n",
    "# Evaluate using MAPE\n",
    "mape = ridge.mean_absolute_percentage_error(y_test, y_pred)\n",
    "print('Mean Absolute Percentage Error on test set:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Ridge Coefficients:\n",
      " [-2507.27129255  3433.75862619 -3502.07202551  -395.37711319\n",
      " -2888.56095915  6057.60499375 -2386.8805472  16839.40370955\n",
      " 14402.74411779 -2723.94476838  2041.25236416  4396.88171115]\n",
      "Sklearn Ridge Coefficients:\n",
      " [-2507.27129255  3433.75862619 -3502.07202551  -395.37711319\n",
      " -2888.56095915  6057.60499375 -2386.8805472  16839.40370955\n",
      " 14402.74411779 -2723.94476838  2041.25236416  4396.88171115]\n"
     ]
    }
   ],
   "source": [
    "# Custom Ridge Regression implementation\n",
    "ridge_custom = RidgeRegression(lambda_=1.0, scaler=MinMaxScaler())\n",
    "ridge_custom.fit(X_train, y_train)\n",
    "beta_custom = ridge_custom.coef_\n",
    "\n",
    "# Sklearn Ridge Regression\n",
    "ridge_sklearn = SklearnRidge(alpha=1.0, fit_intercept=False)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "ridge_sklearn.fit(X_train_scaled, y_train)\n",
    "beta_sklearn = ridge_sklearn.coef_\n",
    "\n",
    "# Compare coefficients\n",
    "print('Custom Ridge Coefficients:\\n', beta_custom)\n",
    "print('Sklearn Ridge Coefficients:\\n', beta_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Ridge Mape: 0.10619804484642713\n",
      "Sklearn Ridge Mape: 0.10619804484642725\n"
     ]
    }
   ],
   "source": [
    "# Predictions and comparison\n",
    "y_pred_custom = ridge_custom.predict(X_test)\n",
    "y_pred_sklearn = ridge_sklearn.predict(scaler.transform(X_test))\n",
    "\n",
    "# Compare predictions\n",
    "# print('Custom Ridge Predictions:\\n', y_pred_custom)\n",
    "# print('Sklearn Ridge Predictions:\\n', y_pred_sklearn)\n",
    "\n",
    "# Evaluate both models (MSE)\n",
    "mape_custom = mean_absolute_percentage_error(y_test, y_pred_custom)\n",
    "mape_sklearn = mean_absolute_percentage_error(y_test, y_pred_sklearn)\n",
    "\n",
    "print('Custom Ridge Mape:', mape_custom)\n",
    "print('Sklearn Ridge Mape:', mape_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 93126 iterations.\n",
      "MAPE ridge gd: 10.619794902454258\n",
      "Coefficients: [-2507.44970258  3433.77746929 -3501.94836693  -395.28506891\n",
      " -2888.55146574  6057.59845803 -2387.06330472 16839.45701475\n",
      " 14402.69243661 -2723.7887348   2040.74523291  4396.88616884]\n"
     ]
    }
   ],
   "source": [
    "class RidgeGradientDescent:\n",
    "    def __init__(self, lambda_=1.0, alpha=0.01, max_iter=1000, tol=1e-6, scaler=None):\n",
    "        self.lambda_ = lambda_  # Regularization strength\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.max_iter = max_iter  # Maximum number of iterations\n",
    "        self.tol = tol  # Tolerance for stopping criterion\n",
    "        self.coef_ = None  # Coefficients (beta)\n",
    "        if scaler == None:\n",
    "            self.scaler_ = StandardScaler()\n",
    "        else:\n",
    "            self.scaler_ = scaler\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Standardize the features\n",
    "        # self.scaler_ = StandardScaler()\n",
    "        X_scaled = self.scaler_.fit_transform(X)\n",
    "        \n",
    "        n, d = X_scaled.shape\n",
    "        self.coef_ = np.zeros(d)  # Initialize coefficients\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            # Compute predictions\n",
    "            y_pred = X_scaled @ self.coef_\n",
    "            \n",
    "            # Compute the gradient\n",
    "            gradient = -(X_scaled.T @ (y - y_pred)) / n + (self.lambda_ / n) * self.coef_\n",
    "            \n",
    "            # Update coefficients (gradient descent step)\n",
    "            self.coef_ -= self.alpha * gradient\n",
    "            \n",
    "            # Check convergence (if the norm of the gradient is small enough)\n",
    "            if np.linalg.norm(gradient, ord=2) < self.tol:\n",
    "                print(f'Converged after {iteration} iterations.')\n",
    "                break\n",
    "            # self.alpha *= 1 - iteration/self.max_iter\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Standardize the test data using the same scaler as training data\n",
    "        X_scaled = self.scaler_.transform(X)\n",
    "        return X_scaled @ self.coef_\n",
    "\n",
    "    def mean_absolute_percentage_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Percentage Error (MAPE)\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        # Compute predictions and MAPE\n",
    "        y_pred = self.predict(X_test)\n",
    "        return self.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Create the Ridge Regression model using Gradient Descent\n",
    "ridge_gd = RidgeGradientDescent(lambda_=1.0, alpha=0.05, max_iter=100_000, tol=1e-3, scaler=MinMaxScaler())\n",
    "\n",
    "# Fit the model to the training data\n",
    "ridge_gd.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_gd = ridge_gd.predict(X_test)\n",
    "\n",
    "mape_gd = ridge_gd.score(X_test, y_test)\n",
    "print(f'MAPE ridge gd: {mape_gd}')\n",
    "print(f'Coefficients: {ridge_gd.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after 100_000 iterations it has not completely converged.\n",
    "Making alpha (the learning rate) depended on beta may be a good idea..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set MAPE: 7.08%\n",
      "Test set MAPE: 8.04%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['Price']\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, shuffle=True, random_state=42, test_size=0.2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the MLPRegressor model\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(200, 10),  # Two hidden layers with 100 and 50 neurons\n",
    "                   activation='relu',  # Activation function\n",
    "                   solver='adam',  # Optimization method\n",
    "                   max_iter=5000,  # Maximum number of iterations\n",
    "                   random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred = mlp.predict(X_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using MAPE on both train and test sets\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_train_pred) * 100\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_test_pred) * 100\n",
    "\n",
    "print(f'Train set MAPE: {mape_train:.2f}%')\n",
    "print(f'Test set MAPE: {mape_test:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mape of 8% for random forest vs 9.5% for mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegression does quite well. It is faster to train and there are less difficult hyper parameter choices to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set MAPE: 5.54%\n",
      "Test set MAPE: 7.88%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=0.6,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using MAPE on both train and test sets\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_train_pred) * 100\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_test_pred) * 100\n",
    "\n",
    "print(f'Train set MAPE: {mape_train:.2f}%')\n",
    "print(f'Test set MAPE: {mape_test:.2f}%')\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a special type of boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set MAPE: 1.16%\n",
      "Test set MAPE: 7.56%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "est = HistGradientBoostingRegressor(\n",
    "    max_leaf_nodes=10, # prevents overfitting\n",
    "    learning_rate=0.1,\n",
    "    max_iter=1000,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.6,\n",
    ")\n",
    "\n",
    "est.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred = est.predict(X_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = est.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using MAPE on both train and test sets\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_train_pred) * 100\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_test_pred) * 100\n",
    "\n",
    "print(f'Train set MAPE: {mape_train:.2f}%')\n",
    "print(f'Test set MAPE: {mape_test:.2f}%')\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
